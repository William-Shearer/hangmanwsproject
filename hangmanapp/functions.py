# from django.core.files.base import ContentFile
from django.core.files.storage import default_storage
# from django.core.exceptions import ObjectDoesNotExist
from random import randint
import requests
from .models import *

# In case everything fails, these words are a back up word dictionary that will infer there was a problem.
fail_safe = [
    "mistake", "fault", "failure", "miscue", "problem", 
    "problematic", "error", "erroneous", "misread", "flopped", 
    "disaster", "disastrous", "catastrophe", "catastrophic",
    "debacle", "tragic", "tragedy", "fiasco", "shambles" 
]


def get_word(user):
    """
    This is where the story starts for creating a word for the hangman round.
    Important comments from development time have not been suppressed.
    Generally, the application should resume any incomplete game (round).
    This can happen if the player leaves the site before either winning
    or losing that round. To do this, the function should first
    query the use history model for complete == False.
    If there is such a case, the word is returned to the application.
    If all words in the user's history are complete, then a new word is generated by
    one of three ways. API, fallback dictionary, or fail_safe local dictionary.
    When a new user first joins and plays, they will have no initial history.
    this will produce an error for the data base model query. If this happens,
    the application will still obtain a word from one of the three methods,
    but will send an empty query list along instead of an error. This means any
    word that has passed the censor will end up in the final list.
    """
    # First, try to get an incomplete word from the DB.
    # Get the list of user words already in DB, order by reversed id.
    if query_list := UserWordHistory.objects.filter(user = user).order_by("-id"):
        if query_list.first().complete == False:
            # The top word is incomplete in the DB.
            # This goes back to the program, now. Done.
            return query_list.first()
        else:
            # Otherwise, complicated stuff starts here...
            # No need to check if the list exists here. Already done above.
            # Here is a list of the last words in the DB for the user.
            # Note, the first word in the list is the last word in the DB.
            # Remember, the id is in reverse order.
            # This slice should ensure that the user does not see a repeat of a word for 40 rounds.
            return primary_get_word_sequence(user, query_list[:40])
    else:
        print("No list")
        return primary_get_word_sequence(user, [])



def primary_get_word_sequence(user, lq_list):
    """
    A reasonably critical function. Here is what happens.
    1. Check if the API returns a list of words.
    2. If the API fails, check if the the fallback dictionary returns a words.
    3. If all that fails, get a word from the local fail safe word list.
    4. If everything fails, return False. There is a big problem.
    """
    if API_words_sample := get_API_words(lq_list):
        print("Got word from API")
        if word_struct := format_entry(user, API_words_sample[randint(0, len(API_words_sample) - 1)]):
            return word_struct
    elif fallback_words_sample := fallback_data_word(lq_list):
        print("Got word from fall back dictionary")
        if word_struct := format_entry(user, fallback_words_sample[randint(0, len(fallback_words_sample) - 1)]):
            return word_struct
    else:
        print("Got word from fail safe")
        if word_struct := format_entry(user, fail_safe[randint(0, len(fail_safe) - 1)]):
            return word_struct
    return False



def get_API_words(lq_list):
    """
    This function uses Pythons own requests module to query a remote word generator API.
    It attempts recover a number of words from this API. If there are any errors,
    it will return None (interpretation as False for the calling function, primary_get_word_sequence).
    """
    try:
        response = requests.get("https://random-word-api.vercel.app/api?words=20")
        response.raise_for_status()
    except requests.exceptions.ConnectionError:
        print("Connection Error")
        return None
    except requests.exceptions.Timeout:
        print("Timeout Error")
        return None
    except requests.exceptions.HTTPError:
        print("HTTP Error")
        return None
    except requests.exceptions.RequestException:
        print("Request Error")
        return None
    except Exception:
        print("Unknown Error")
        return None
    else:    
        # return response.json()
        try:
            # Put the API words through the censor, and return the remainder.
            return censor_API_words(response.json(), lq_list)
        except (OSError, IndexError) as error:
            print(f"ERROR: {error}")
            # If there are any errors from the censor, just return None to acces the fallback mode.
            return None




def censor_API_words(word_list, lq_list):
    """
    This function purges the list of words obtained from the API of any inappropriate words.
    The censor.txt is located in wordbank, and contains a list of words that are not
    really desirable in a hangman game. In the event that the API provides a word that is
    unacceptable, it will be removed from the list. 
    In addition to that, it will also ensure that all the words in the API list are at least
    five letters long.
    The list comprehension will structure a new list containing all the words that were
    not rejected and return that.
    If, for any reason, all words are rejected and an empty list is produced,
    the function will produce an index error. This error is caught up in the Get_API_words
    function.
    """
    try:
        with open("wordbank/censor.txt", "r") as censor_file:
            try:
                censor_list = censor_file.read().split(" ")
            except Exception as io_error:
                print(f"Error reading file: {io_error}")
                raise OSError
            else:
                # Uhm. Turned into a bit of a major list comprehension.
                censored_words = [word for word in word_list if word not in censor_list and word not in lq_list and len(word) > 4]
                # What happens if the censor eliminated all the words?
                if len(censored_words) > 0:
                    return censored_words
                else:
                    print("Error in API Censor, all elements were suppressed.")
                    raise IndexError
    except Exception as file_error:
        print(f"Error opening file: {file_error}")
        raise OSError


def fallback_data_word(lq_list):
    """
    If the word API response has failed, this function recovers a word from a local text file
    that contains a list of words that can be used in the application to play hangman.
    There is no need to censor this file, as it is practically guaranteed not to contain
    inapproriate words.
    Additionally, all words in this file will be longer than 4 words, so there
    is no need to include that condition in the list comprehension,
    as there was in the API recovery method (where many words might be
    four letters long or less).
    lq_list is a list of words from the DB that the user has already solved.
    It is checked here in the list comprehension so that the user will not have
    to (too frequently) run the risk of getting repeat words too soon.
    """
    try:
        with open("wordbank/nouns_en.txt", "r") as fallback_file:
            try:
                fallback_word_list = fallback_file.read().split(" ")
            except Exception as io_error:
                print(f"Error reading file: {io_error}")
                return False
            else:
                fallback_sample_list =  [word for word in fallback_word_list if word not in lq_list]
                if len(fallback_sample_list) > 0:
                    return fallback_sample_list
                else:
                    return fail_safe
                
    except Exception as file_error:
        print(f"Error opening file: {file_error}")
        return False
    

def format_entry(user, word):
    """
    This function writes a new word to the user's word history model,
    when the word is retrieved for the first time.
    It should work normally without problems, main reason for failure being
    unmigrated or altered model in models.py.
    If this does fail, it is a serious problem for the application,
    and the server should be brought down to fix the issues in model.py.
    """
    try:
        new_DB_word = UserWordHistory.objects.create(
            user = user,
            word = word,
            player_word = "_" * len(word),
            used_letters = ""
        )
    except Exception as error:
        print(f"ERROR: Not kidding. Big DB error: {error}\nBring the server down and see what is happening.")
        return False
    else:
        return new_DB_word


def clean_censor():
    """
    A utility function not used by the application.
    Its purpose is to strip the censor file located at 
    https://github.com/whomwah/language-timothy/blob/master/profanity-list.txt
    of words with spaces or words that contain non alpha characters.
    It is to be run from shell, with the text file in the same folder.
    Once the censor file is purged, it should be placed in the wordbank directory.
    """
    with open("en.txt", "r") as file:
        words = []
        words = file.readlines()

    new_list = []
    for word in words:
        if word.replace("\n", "").isalpha():
            new_list.append(word.replace("\n", ""))

    with open("censor.txt", "w") as file:
        for word in new_list:
            file.write(word + " ")


def get_win_ratio():
    records = UserWordHistory.objects.all()
    users = User.objects.all()
            